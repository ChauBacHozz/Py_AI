{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GF</th>\n",
       "      <th>TBS</th>\n",
       "      <th>Natri Benzoate</th>\n",
       "      <th>Abs 260</th>\n",
       "      <th>Abs 265</th>\n",
       "      <th>Abs 270</th>\n",
       "      <th>Abs 275</th>\n",
       "      <th>Abs 280</th>\n",
       "      <th>Abs 285</th>\n",
       "      <th>Abs 290</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.143</td>\n",
       "      <td>1.283</td>\n",
       "      <td>1.128</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GF   TBS  Natri Benzoate  Abs 260  Abs 265  Abs 270  Abs 275  Abs 280  \\\n",
       "0   3.0  3.0             3.0    0.333    0.452    0.584    0.625    0.534   \n",
       "16  0.5  0.5             2.5    0.164    0.180    0.202    0.190    0.151   \n",
       "23  0.5  1.0             1.0    0.123    0.145    0.171    0.175    0.152   \n",
       "26  2.5  2.5             0.5    0.222    0.323    0.433    0.486    0.427   \n",
       "32  2.5  3.0             2.5    0.340    0.446    0.565    0.603    0.519   \n",
       "17  0.5  0.5             3.0    0.190    0.206    0.229    0.211    0.166   \n",
       "21  0.5  2.5             0.5    0.129    0.174    0.227    0.262    0.247   \n",
       "33  2.5  1.0             0.5    0.210    0.294    0.381    0.410    0.346   \n",
       "31  2.5  3.0             2.0    0.308    0.416    0.536    0.580    0.503   \n",
       "5   3.0  3.0             0.5    0.251    0.376    0.512    0.576    0.505   \n",
       "30  2.5  3.0             1.5    0.290    0.400    0.522    0.571    0.498   \n",
       "41  1.5  2.5             2.0    0.191    0.248    0.319    0.348    0.308   \n",
       "2   7.0  7.0             2.0    0.575    0.848    1.143    1.283    1.128   \n",
       "7   2.0  2.0             1.5    0.219    0.302    0.392    0.425    0.365   \n",
       "29  2.5  3.0             0.5    0.250    0.359    0.480    0.540    0.480   \n",
       "38  1.0  2.5             1.5    0.198    0.256    0.322    0.351    0.313   \n",
       "12  0.5  0.5             0.5    0.081    0.101    0.122    0.129    0.113   \n",
       "24  2.5  2.5             1.5    0.265    0.364    0.475    0.520    0.452   \n",
       "8   2.0  2.0             1.0    0.204    0.286    0.375    0.412    0.358   \n",
       "10  1.0  1.0             1.0    0.130    0.170    0.214    0.227    0.194   \n",
       "27  2.5  2.5             2.0    0.283    0.382    0.493    0.530    0.454   \n",
       "25  2.5  2.5             1.0    0.251    0.353    0.465    0.513    0.448   \n",
       "22  0.5  3.0             0.5    0.153    0.203    0.263    0.304    0.288   \n",
       "19  0.5  1.5             0.5    0.103    0.135    0.172    0.192    0.176   \n",
       "43  1.2  1.5             1.0    0.163    0.238    0.323    0.372    0.337   \n",
       "6   2.0  2.0             2.0    0.238    0.319    0.409    0.435    0.370   \n",
       "34  2.5  1.0             1.0    0.231    0.313    0.397    0.418    0.349   \n",
       "15  0.5  0.5             2.0    0.119    0.139    0.161    0.161    0.136   \n",
       "11  1.0  1.0             0.5    0.115    0.156    0.201    0.218    0.190   \n",
       "39  1.0  2.5             1.0    0.175    0.234    0.301    0.336    0.304   \n",
       "1   3.0  3.0             2.0    0.301    0.423    0.556    0.608    0.526   \n",
       "28  2.5  2.5             2.5    0.307    0.406    0.520    0.552    0.471   \n",
       "20  0.5  2.0             0.5    0.117    0.156    0.201    0.229    0.214   \n",
       "3   3.0  3.0             1.5    0.283    0.405    0.537    0.592    0.513   \n",
       "4   3.0  3.0             1.0    0.263    0.386    0.519    0.577    0.503   \n",
       "36  2.5  1.0             2.0    0.278    0.361    0.450    0.460    0.377   \n",
       "14  0.5  0.5             1.5    0.124    0.142    0.164    0.161    0.134   \n",
       "35  2.5  1.0             1.5    0.249    0.331    0.418    0.435    0.358   \n",
       "18  0.5  1.0             0.5    0.097    0.124    0.154    0.167    0.151   \n",
       "13  0.5  0.5             1.0    0.107    0.126    0.148    0.149    0.126   \n",
       "42  1.5  2.5             2.5    0.235    0.290    0.360    0.380    0.329   \n",
       "40  1.0  2.5             0.5    0.154    0.214    0.281    0.321    0.294   \n",
       "9   2.0  2.0             0.5    0.188    0.272    0.361    0.401    0.350   \n",
       "37  2.5  1.0             2.5    0.293    0.374    0.462    0.468    0.380   \n",
       "\n",
       "    Abs 285  Abs 290  \n",
       "0     0.240    0.052  \n",
       "16    0.071    0.035  \n",
       "23    0.089    0.047  \n",
       "26    0.210    0.052  \n",
       "32    0.251    0.073  \n",
       "17    0.076    0.037  \n",
       "21    0.161    0.059  \n",
       "33    0.145    0.044  \n",
       "31    0.243    0.064  \n",
       "5     0.238    0.054  \n",
       "30    0.244    0.064  \n",
       "41    0.163    0.033  \n",
       "2     0.534    0.113  \n",
       "7     0.168    0.041  \n",
       "29    0.246    0.069  \n",
       "38    0.177    0.055  \n",
       "12    0.063    0.032  \n",
       "24    0.219    0.055  \n",
       "8     0.171    0.046  \n",
       "10    0.094    0.032  \n",
       "27    0.210    0.048  \n",
       "25    0.218    0.055  \n",
       "22    0.193    0.076  \n",
       "19    0.108    0.044  \n",
       "43    0.185    0.044  \n",
       "6     0.166    0.039  \n",
       "34    0.146    0.046  \n",
       "15    0.072    0.036  \n",
       "11    0.095    0.033  \n",
       "39    0.174    0.054  \n",
       "1     0.241    0.052  \n",
       "28    0.216    0.051  \n",
       "20    0.138    0.052  \n",
       "3     0.237    0.052  \n",
       "4     0.234    0.050  \n",
       "36    0.149    0.043  \n",
       "14    0.068    0.034  \n",
       "35    0.144    0.041  \n",
       "18    0.090    0.040  \n",
       "13    0.067    0.033  \n",
       "42    0.169    0.037  \n",
       "40    0.172    0.055  \n",
       "9     0.168    0.046  \n",
       "37    0.147    0.041  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"MTND2.xlsx\")\n",
    "data = data.drop(\"STT\", axis = 1)\n",
    "data = data.sample(frac=1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 7)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test data\n",
    "data_train = data[:int(0.7 * len(data))].values\n",
    "data_test = data[int(0.7 * len(data)):].values\n",
    "# Convert data table to X and Y matricses\n",
    "X_train = data_train[:,0:3].astype(float) \n",
    "Y_train = data_train[:,3:].reshape(-1, 7).astype(float)\n",
    "X_test = data_test[:,0:3].astype(float) \n",
    "Y_test = data_test[:,3:].reshape(-1, 7).astype(float)\n",
    "print(Y_train.shape)\n",
    "# np.linalg.det(np.dot(X_train.T, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_chunks = np.array_split(Y_train, len(Y_train) / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chunks = np.array_split(X_train, len(Y_train) / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes = int((Y_train.shape[0] / (2 * (Y_train.shape[1] + X_train.shape[1]))))\n",
    "print(hidden_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTIVATION FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(input):\n",
    "    return np.maximum(input, 0)\n",
    "def leaky_ReLU(input):\n",
    "    return np.maximum(0.01 * input, input)\n",
    "def Linear(input):\n",
    "    return input\n",
    "def Sigmoid(input):\n",
    "    return 1 / (1 + np.exp(-input))\n",
    "def Swish(input):\n",
    "    return input * Sigmoid(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_de(input):\n",
    "    return (input > 0) * 1\n",
    "def leaky_ReLU_de(input):\n",
    "    if input >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.01\n",
    "def Linear_de(input):\n",
    "    return 1\n",
    "def Sigmoid_de(input):\n",
    "    return np.exp(input)/ np.square(np.exp(input) + 1)\n",
    "def Swish_de(input):\n",
    "    return Swish(input) + Sigmoid(input)*(1 - Swish(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriative_func(func_list):\n",
    "    deriative_funcs = []\n",
    "    for func in func_list:\n",
    "        if func.__name__ == \"ReLU\":\n",
    "            deriative_funcs.append(ReLU_de)\n",
    "        if func.__name__ == \"leaky_ReLU\":\n",
    "            deriative_funcs.append(leaky_ReLU_de)\n",
    "        if func.__name__ == \"Linear\":\n",
    "            deriative_funcs.append(Linear_de)\n",
    "        if func.__name__ == \"Sigmoid\":\n",
    "            deriative_funcs.append(Sigmoid_de)\n",
    "        if func.__name__ == \"Swish\":\n",
    "            deriative_funcs.append(Swish_de)\n",
    "    return deriative_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, n_inputs, n_outputs, n_hiddenlayers, n_hiddenlayernodes_list, layerfunc_list):\n",
    "        self.n_hiddenlayers = n_hiddenlayers\n",
    "        # Init weights list\n",
    "        self.weights = []\n",
    "        self.weights.append(np.random.rand(n_inputs, n_hiddenlayernodes_list[0]))\n",
    "        for i in range(1, n_hiddenlayers):\n",
    "            self.weights.append(np.random.rand(n_hiddenlayernodes_list[i - 1], n_hiddenlayernodes_list[i]))\n",
    "        self.weights.append(np.random.rand(n_hiddenlayernodes_list[n_hiddenlayers - 1], n_outputs))\n",
    "        \n",
    "        # Init bias list\n",
    "        self.bias = []\n",
    "        for i in n_hiddenlayernodes_list:\n",
    "            self.bias.append(np.zeros((1, i)))\n",
    "        self.bias.append(np.zeros((1, n_outputs)))\n",
    "        # for i in range (len(self.bias)):\n",
    "        #     print(self.bias[i].shape)\n",
    "\n",
    "        # Init deriative functions list\n",
    "        self.deriative_funcs = deriative_func(layerfunc_list)\n",
    "        # print(len(self.weights))\n",
    "    def fit(self, input_data, target_data, iter):\n",
    "        for i in range (iter):\n",
    "            # FORWARD PASS\n",
    "            layer_inputs = []\n",
    "            layer_outputs = [input_data]\n",
    "            for i in range (0, self.n_hiddenlayers + 1):\n",
    "                layer_inputs.append(np.dot(layer_outputs[i], self.weights[i]) + self.bias[i])\n",
    "                layer_outputs.append(self.deriative_funcs[i](layer_inputs[i]))\n",
    "            # BACKPROPAGATION\n",
    "            l3_delta = l3_output - target_data\n",
    "            d_weight3 = np.dot(l2_output.T, l3_delta)\n",
    "            d_bias3 = np.dot(np.ones((1, l3_delta.shape[0])), l3_delta)\n",
    "\n",
    "            l2_delta = np.dot(l3_delta, self.weight3.T) * ReLU_de(l2_input)\n",
    "            d_weight2 = np.dot(l1_output.T, l2_delta)\n",
    "            d_bias2 = np.dot(np.ones((1, l2_delta.shape[0])), l2_delta)\n",
    "\n",
    "            l1_delta = np.dot(l2_delta, self.weight2.T) * ReLU_de(l1_input)\n",
    "            d_weight1 = np.dot(input_data.T, l1_delta)\n",
    "            d_bias1 = np.dot(np.ones((1, l1_delta.shape[0])), l1_delta)\n",
    "\n",
    "            self.weight3 -= 0.001 * d_weight3\n",
    "            self.bias3 -= 0.001 * d_bias3\n",
    "            self.weight2 -= 0.001 * d_weight2\n",
    "            self.bias2 -= 0.001 * d_bias2\n",
    "            self.weight1 -= 0.001 * d_weight1\n",
    "            self.bias1 -= 0.001 * d_bias1\n",
    "\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        l1_input = np.dot(input_data, self.weight1) + self.bias1\n",
    "        l1_output = ReLU(l1_input)\n",
    "\n",
    "        l2_input = np.dot(l1_output, self.weight2) + self.bias2\n",
    "        l2_output = ReLU(l2_input)\n",
    "\n",
    "        l3_input = np.dot(l2_output, self.weight3) + self.bias3\n",
    "        l3_output = l3_input\n",
    "        return l3_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 3)\n",
      "[array([[1.67066602, 0.67888505, 0.64520535],\n",
      "       [0.61112623, 0.23268858, 0.22418398],\n",
      "       [0.55829589, 0.2231928 , 0.21567422],\n",
      "       [1.27616547, 0.53105219, 0.50535151],\n",
      "       [1.67458113, 0.67890037, 0.64924465],\n",
      "       [0.68618075, 0.25908082, 0.25003215],\n",
      "       [0.76871761, 0.32389776, 0.31909968],\n",
      "       [1.08478384, 0.4417821 , 0.41146845],\n",
      "       [1.57984305, 0.64529182, 0.61669156],\n",
      "       [1.48061673, 0.61831128, 0.58434677]]), array([[0.32052132, 0.18726138, 0.40655007, 0.23444774],\n",
      "       [0.416937  , 0.28074568, 0.49064506, 0.28297685],\n",
      "       [0.41990308, 0.28397994, 0.49287364, 0.28424907],\n",
      "       [0.35914609, 0.22428113, 0.44067296, 0.25415144],\n",
      "       [0.32012637, 0.18692586, 0.40610821, 0.23426261],\n",
      "       [0.41200486, 0.27566392, 0.48663577, 0.28068492],\n",
      "       [0.40477726, 0.26921184, 0.47972415, 0.27674909],\n",
      "       [0.37833651, 0.24240461, 0.45797441, 0.26403998],\n",
      "       [0.32927386, 0.19561389, 0.41428013, 0.23896825],\n",
      "       [0.33856319, 0.20472221, 0.42236309, 0.24351093]]), array([[2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569]]), array([[3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938]])]\n",
      "[array([[1.5415859 , 0.63365521, 0.60512777],\n",
      "       [0.96208871, 0.39338336, 0.38487272],\n",
      "       [3.31660305, 1.38076794, 1.31133543],\n",
      "       [1.13459092, 0.46353627, 0.43997244],\n",
      "       [1.44388387, 0.60215814, 0.57504689],\n",
      "       [1.01110477, 0.41381575, 0.40410955],\n",
      "       [0.39375379, 0.15929982, 0.15253675],\n",
      "       [1.39811906, 0.57396888, 0.54810926],\n",
      "       [1.10090491, 0.45324072, 0.43034767],\n",
      "       [0.63745032, 0.25794601, 0.24548671]]), array([[0.33287108, 0.19912881, 0.41739844, 0.24075546],\n",
      "       [0.38905078, 0.2533467 , 0.4666085 , 0.26922684],\n",
      "       [0.1834225 , 0.07803015, 0.26311318, 0.150976  ],\n",
      "       [0.37342521, 0.2377757 , 0.4534902 , 0.26154386],\n",
      "       [0.34218032, 0.20822733, 0.42545185, 0.24539131],\n",
      "       [0.38464565, 0.24901074, 0.46282804, 0.26705209],\n",
      "       [0.42848223, 0.29271515, 0.49995378, 0.2882982 ],\n",
      "       [0.34735767, 0.21277166, 0.43044558, 0.24828821],\n",
      "       [0.37643538, 0.24083751, 0.45597197, 0.26297126],\n",
      "       [0.41483812, 0.27887411, 0.4886649 , 0.28180766]]), array([[2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569]]), array([[3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938]])]\n",
      "[array([[1.4251676 , 0.57976968, 0.55262058],\n",
      "       [1.368094  , 0.56452891, 0.53808062],\n",
      "       [0.90836006, 0.38274247, 0.37759662],\n",
      "       [0.56835574, 0.23610934, 0.22982892],\n",
      "       [0.98926671, 0.41641702, 0.40336421],\n",
      "       [1.17321183, 0.47510467, 0.45127751],\n",
      "       [1.13008567, 0.45542994, 0.42559054],\n",
      "       [0.50711185, 0.19956667, 0.19220306],\n",
      "       [0.60485601, 0.24810133, 0.23578471],\n",
      "       [0.95244959, 0.39439174, 0.38447543]]), array([[0.34498857, 0.21029373, 0.42856962, 0.24719902],\n",
      "       [0.35021946, 0.21558666, 0.43291409, 0.24969305],\n",
      "       [0.39320463, 0.25782606, 0.46976174, 0.27105471],\n",
      "       [0.4190401 , 0.28328871, 0.49196604, 0.28373311],\n",
      "       [0.38615483, 0.25079449, 0.4638523 , 0.26758992],\n",
      "       [0.3699427 , 0.23424008, 0.45060779, 0.25989229],\n",
      "       [0.37429591, 0.23830161, 0.454626  , 0.26212841],\n",
      "       [0.42293455, 0.28699904, 0.49544406, 0.28572049],\n",
      "       [0.41688443, 0.28100331, 0.49030709, 0.28274611],\n",
      "       [0.38971064, 0.25412213, 0.46705989, 0.26946557]]), array([[2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569],\n",
      "       [2.79827301, 2.16427041, 1.74443687, 1.59401474, 2.17195569]]), array([[3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938],\n",
      "       [3.3409156 , 1.8197593 , 1.34901938]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Neural_Network' object has no attribute 'weight1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\VS_Workspace\\Py_AI\\neural_network.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(Y_chunks[i], X_chunks[i], \u001b[39m1000\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(ReLU(Y_train))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(model.predict(Y_test))\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(Y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(X_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test)\n",
      "\u001b[1;32mc:\\VS_Workspace\\Py_AI\\neural_network.ipynb Cell 12\u001b[0m in \u001b[0;36mNeural_Network.predict\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, input_data):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     l1_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(input_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight1) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     l1_output \u001b[39m=\u001b[39m ReLU(l1_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/VS_Workspace/Py_AI/neural_network.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     l2_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(l1_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight2) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias2\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Neural_Network' object has no attribute 'weight1'"
     ]
    }
   ],
   "source": [
    "model = Neural_Network(Y_train.shape[1], X_train.shape[1],3, [3,4,5], [Sigmoid, ReLU, ReLU, Linear])\n",
    "# print(len(Y_chunks))\n",
    "for i in range(len(Y_chunks)):\n",
    "    model.fit(Y_chunks[i], X_chunks[i], 1000)\n",
    "# print(ReLU(Y_train))\n",
    "# print(model.predict(Y_test))\n",
    "X_pred = model.predict(Y_test)\n",
    "print(X_pred)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-35.42103363 107.01465378 162.76902756]\n",
      " [ 69.03921515 -50.82291848 178.03013407]\n",
      " [-11.36806531   7.05432278 -19.31722388]\n",
      " [-23.84852749 -27.81432296  43.62188531]\n",
      " [-10.75546377   9.76207671  25.2680018 ]\n",
      " [-14.73167458   3.3783414   22.0250844 ]\n",
      " [ 12.75348593  12.87854881 -52.22467765]\n",
      " [-23.84852749  44.37135409  -4.25207646]\n",
      " [-15.43185951   2.61313161 144.46688145]\n",
      " [-11.53036895 -29.75904854 -32.88221986]\n",
      " [ -8.64064896  12.07329041 -16.83761678]\n",
      " [122.13692934 -49.34763214 172.76331386]\n",
      " [-28.56436469 125.74824118 -13.54385827]\n",
      " [-17.95442749   1.8945587  154.10636894]]\n"
     ]
    }
   ],
   "source": [
    "print(((X_pred - X_test) / X_test ) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1658d7c139ecb4375ab76a4a9bda7b71499aefd554bc284ea3c47687afb5394a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
